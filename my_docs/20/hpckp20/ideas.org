Here are some notes for my talk at HPCKP'20

XALT:


* What is XALT?
** Tracks program execution on your cluster
** It can track what program run on your system 
** And what libraries are used
** Optionally can track "imports" in Python, R, MATLAB (PKGS)
** XALT is a census taker, NOT a performance tool
** Extremely light weight: execution penalty (~ 0.001 secs)
** Generate *.json records
** XALT provides a MYSQL database to hold information.
** XALT collection runs as user.
    XALT takes extreme measures to protect itself from users
* Documentation found at xalt.readthedocs.io
* Brief History 
** XALT was a NSF funded project.
** Work has continued because TACC (and others) have found it useful
** Original version only tracked mpi program execution
* How does it work: Two Parts
** LD wrapper
** ELF trick to record 
* LD wrapper
** Linux compiler call ld to build the executable in an ELF format
** XALT provides an LD wrapper script
*** It injects a watermark that knows the build user, the modules, the machine, ...
*** Records the shared libraries that built the executable
*** Generates a *.json record that can be stored in a database
* ELF Trick
** Show how simple example with ./try
** Show what happens with ls
** Show source fix to capture stderr
** Show what happens with ls version 2
* What one might do with the data?
** Top 20 executables (MPI/not MPI), SU, number, users
** GPU usage
** Code for benchmarking
** Track Field of Science usage
** Chemistry Code and memory usage example
* Installing XALT
** It is easy and hard to install XALT
   ./configure --prefix ...; make install
   This part is responsible for the *.json file generation
** Site's configuration file: 
** Transport method: Syslog, File, Curl?
** What to do with the generated json records?
*** Use MySQL supplied DB?
*** Use your own solution?
*** Must deal with 1 to N relations
    an execution has multiple libraries, multiple env vars etc.
** Where to store the data?
   Use a VM, use something larger like a Apache Cassandra
* Reverse Map:  path to modules? Use Lmod to generate?
* How to get XALT's LD wrapper before compiler's ld?
** Use Lmod, or move compiler's ld to ld.x every time 
** Or treat every executable like ls or commercial code?
* Transport method
** Syslog
   Instruction for working with rsyslog daemon
   This does require some rsyslog knowledge to get it to work
   TACC uses this method for most systems
** File
   Json files are written to a write only public location on the cluster
   A program run by root collects *.json files and inserts records into a MySQL db 
   TACC uses this method on our Cray.
** Curl 
   This transport method is used by Swiss CSCS.
* Site Config.py file
** Each site must configure XALT to match their setup
** What hosts to collect on? 
   Use hostname -f to determine compute nodes?
** What executable to track, to ignore?
** What executables are PKGS? 
   Interested in tracking import?  
   Support for python 2/3, MATLAB, R package import
** What python packages to track or ignore?
** What are the sampling rules?
* How the site config.py file is used
** The XALT build process reads this file and generates some *.h file 
   These *.h files get used by the XALT C library and some C++ programs.
   Therefore any changes to the Site config.py file will only be noticed when XALT is rebuilt.
   This is done for speed. 
   Most files are used to build (f)lex routines to speed regex matching.
** XALT provides a xalt_configuration_report.
   This program to let you (and maybe me?) how your site has configured XALT
** Control the recorded environment variables.
   Only want a small number of env. vars per execution.
** Sampling rules
** Python package imports recording rules.
* Optionally XALT can sample the executable by runtime.
  That is XALT will randomly track some executions and not record others.
* How sampling works
  The start record would record the start time and set the end time to zero at the start of the execution. 
  The end record was the same as the start record, and it send the end time.
  This was the original design of XALT 
  When it became clear that the XALT db could get swamped with data, the rules changed.
  Now all scalar (non-MPI) programs only produce an end record. 
  This means that a scalar program execution will only have the
    possibility of a record in XALT if it completed main() and didn't
    terminate early.
  XALT has signal handlers to catch SEGV Faults, FPE, etc. If caught,
    -> end record
  XALT uses the runtime to control sampling results. TACC current uses
  for scalar (non-MPI) executions (num_tasks = 1)
      0     to  30 min. 0.0001 chance of recording
     30 min to 120 min. 0.01   chance of recording
    120 min to inf.     1.0    chance of recording
  XALT uses for MPI programs (num_task 2 to 127):
      0     to  15 min. 0.0001 chance of recording
     15 min to  30 min. 0.01   chance of recording
     30 min to inf.     1.0    chance of recording
  
  XALT produces a start and end record for num_task >= 128 independent
  of run time.

  XALT must handle the case of long running MPI programs that run for
  24 or 48 hours that do not terminate. They write restart files to
  restart the calculation.  

  XALT assumes that if there is only a start record and no end-time
  then the end-time of the job is the endtime of the execution.  (Must
  be added later.

* What one does with the data?
* Where is XALT used?
  Show google analytics results
* Conclusion



